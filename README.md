<h1 align="center">Projet Computer Vision :  DÃ©tection de renards dans les poulaillers</h1>

<p align="center">
  <i>IngÃ© 3I - 19/02/2026
</i>
</p>

<p align="center">
    CRUEYZE RaphaÃ«l - HAROUNYAN NatalÃ¨ne - PADRINO Gabriel - ZARGOUNI Yacine
</p>

<p align="center">
  <img src="https://img.shields.io/badge/python-3.10+-green" />
<br/>

---

## ğŸ“‘ Table des matiÃ¨res

- [1. Introduction au projet](#1-introduction-au-projet)
- [2. Dataset personnalisÃ©](#2-dataset-personnalisÃ©)
- [3. Entrainement des diffÃ©rents modÃ¨les](#3-entrainement-des-diffÃ©rents-modÃ¨les)
- [4. Conclusion](#4-conclusion)

<br/>

Les diapositives du projet sont disponibles dans le document : ```PrÃ©sentation_RenardsPoulailler_ComputerVision_CRUEYZE_HAROUNYAN_PADRINO_ZARGOUNI.pptx```
<br/>

---

## 1. Introduction au projet
<p align="justify">
On a tous connu une gentille poule, morte dans dâ€™atroces souffrances Ã  cause dâ€™unâ€¦ Renard. 
La vÃ´tre sâ€™appelait sans doute Â«Â poupouleÂ Â», Â«Â pouletteÂ Â», Â«BÃ©rÃ©nice Â»â€¦

C'est pourquoi l'entreprise <b>Poul-ai-ller</b> a mis en place son systÃ¨me NugGet-Information. 

GrÃ¢ce Ã  lui, fini les nuits stressantes Ã  imaginer le pire pour vos poules : vous pouvez suivre en direct votre poulailler et Ãªtre averti lorsquâ€™un renard pointe le bout de son nez ! 
</p>

<p align="center">
  <img src="Images_Readme\logo_poulailler.jpg" width="80%"/>
  <br>
  <em>Figure 1 â€“ Logo du projet Chicken & Fox Detection</em>
</p>

<br/>

---
## 2. Dataset personnalisÃ©
<p align="justify">
Le dataset COCO ne contenant pas les classes chicken et fox, nous avons constituÃ© un dataset personnalisÃ© Ã  partir de 15 vidÃ©os YouTube variÃ©es. Nous avons extrait uniquement les sÃ©quences pertinentes (7 Ã  10 secondes) afin dâ€™obtenir des images reprÃ©sentatives.

Le dataset inclut des images en RGB et en niveaux de gris, avec des points de vue variÃ©s et des individus Ã  diffÃ©rentes Ã©chelles pour garantir une bonne diversitÃ©.

Les annotations ont toutes Ã©tÃ© rÃ©alisÃ©es manuellement. Le jeu de donnÃ©es final comprend :
 <ul>
  <li>1041 images</li>
  <li>3114 bounding boxes</li>
  <li>3 classes : chicken, fox et background</li>
</ul>

Les images ont ensuite Ã©tÃ© rÃ©aprties en groupes d'entrainement (_train_) de validation (_valid_) et de _test_ avec une proportion respective de 70%, 20% et 10%.
</p>

<p align="center">
  <img src="Images_Readme\2_trainTestVal.png"/>
  <br>
  <em>Figure 2 â€“ SÃ©paration des images train, valid et test</em>
</p>

<table align="center">
  <tr>
    <td align="center">
      <img src="Images_Readme\2_heatMap.png" width="90%"/><br>
      <em>Figure 3 â€“ Carte de chaleur des annotations</em>
    </td>
    <td align="center">
      <img src="Images_Readme\2_histogram.png" width="100%"/><br>
      <em>Figure 4 â€“ Histogramme du nombre d'objets par image</em>
    </td>
  </tr>
</table>

---
## 3. Entrainement des diffÃ©rents modÃ¨les

- [A. Les modÃ¨les non-retenus](#a-les-modÃ¨les-non-retenus)
- [B. Les modÃ¨les entrainÃ©s](#b-les-modÃ¨les-entrainÃ©s)

### A. Les modÃ¨les non-retenus

<p align="justify">
Nous avons testÃ© le modÃ¨le <b>SAM2</b> (Segment Anything Model 2). Il s'agit d'un modÃ¨le de segmentation guidÃ©e par prompt : il ne fait pas de dÃ©tection dâ€™objets autonome (pas de bounding boxes classifiÃ©es).

Or SAM2 ne fait pas de dÃ©tection multi-classes ou de classification, donc nous nous sommes donc uniquement intÃ©ressÃ©s Ã  des modÃ¨les de dÃ©tection.
</p>

<p align="center">
  <img src="Images_Readme\3_SAM2.png"
  width="80%"/><br>
  <em>Figure 5 â€“ Test de segmentation via SAM2</em>
</p>
<br>

<p align="justify">
Nous avons par la suite testÃ© le modÃ¨le <b>YOLOv8</b> prÃ©-entraÃ®nÃ© sur COCO. Il s'agit d'un modÃ¨le de dÃ©tection dâ€™objets temps rÃ©el entrainÃ© sur 80 classes prÃ©sente dans le dataset COCO.

NÃ©anmoins en raison de faibles performances sur des domaines spÃ©cifiques et de l'absence de classes "poule" et "renard" nous avons dÃ©clinÃ© cette option.
</p>

<p align="center">
  <img src="Images_Readme\3_YOLO8.png"
  width="100%"/><br>
  <em>Figure 6 â€“ Test de dÃ©tection via YOLO8 prÃ©-entrainÃ© sur le dataset COCO</em>
</p>

### B. Les modÃ¨les entrainÃ©s
Nous avons finalement sÃ©lectionnÃ© 3 modÃ¨les pour l'entrainement : 
 <ul>
  <li>YOLO 11 : l'entrainement se trouve dans <code>YOLO\Inference_YOLO_11.ipynb</code></li>
  <li>YOLO 26 : l'entrainement se trouve dans <code>YOLO\Inference_YOLO_26.ipynb</code></li>
  <li>RF-DETR : l'entrainement se trouve dans <code>RF-DETR\RFDETR.ipynb</code></li>
</ul>

<p align="justify">
Chaque modÃ¨le a Ã©tÃ© entrainÃ© sur l'ensemble <i>d'entrainement</i> et des mÃ©triques et rÃ©sultats ont Ã©tÃ© dÃ©duits des ensembles de <i>validation</i> et de <i>test</i>.

Afin de tester la robustesse de nos modÃ¨les face Ã  de nouvelles images, des tests on Ã©tÃ© rÃ©alisÃ©s sur deux "types" d'images provenant de sources extÃ©rieures au dataset :
<ul>
  <li>Un test sur des images avec <b>d'autres volatiles</b> que des poules (ici des oies) : les ressources images sont <code>Images_test\Poules_Oie.png</code> et <code>Images_test\Poules_Oies_2.png</code></li>

  <li>Un test sur des images avec <b>beaucoup de poules</b> pour vÃ©fifier si le modÃ¨le peut dÃ©tecter plus de 3/4 poules : les ressources images sont <code>Images_test\Poules_Multiple.png</code> et <code>Images_test\Poules_Nombreuses.png</code></li>
</ul>

</p>

Les scripts d'entrainement s'articulent selon :
```text
Entrainement â”€â”€â–¶ Load des donnÃ©es et entrainement
             â”œâ”€â–¶ MÃ©triques d'Ã©valuation

Validation â”€â”€â”€â”€â–¶ MÃ©triques de validation

Test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ MÃ©triques de test
             â”œâ”€â–¶ Test sur des images du dataset
             â”œâ”€â–¶ Test sur des images hors dataset
```

---
## 4. Conclusion
<p align="justify">
<i>Quelle est donc la meilleure solution pour nos poules ?
</i>

Afin de tester la robustesse de nos modÃ¨les face Ã  de nouvelles images, des tests on Ã©tÃ© rÃ©alisÃ©s sur deux "types" d'images provenant de sources extÃ©rieures au dataset :
<ul>
  <li><b>YOLO-11</b> est le modÃ¨le le plus rapide et le moins coÃ»teux, a de trÃ¨s bons rÃ©sultats sur les images de test du dataset mais il manque de rappel : il ne dÃ©tecte pas tous les oiseaux (difficultÃ© de gÃ©nÃ©ralisation sur des images hors dataset).</li>
  
  <li><b>YOLO-26</b> a les scores de prÃ©cision le plus faible et gÃ©nÃ¨re des faux positifs, notamment en Â« hallucinant Â» des renards, ce qui peut entraÃ®ner des alertes inutiles.</li>

  <li><b>RF-DETR</b> offre les meilleures performances globales, mais son implÃ©mentation est nettement plus coÃ»teuse en ressources (30 Go contre 10Go pour YOLO-11 et 12Go pour YOLO-26).</li>
</ul>

</p>

<p align="center">
<i>Merci d'avoir fait appel Ã  <b>Poul-ai-ller</b> !!!</i>
</p>
<p align="center">
  <img src="Images_Readme\logo_poulailler.jpg" width="60%"/>
  <br>
</p>

<br>
<p align="center">
Et merci pour cette annÃ©e ğŸ˜‰ğŸ’š
</p>